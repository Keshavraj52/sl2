{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e80d1c69",
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "\n",
        "# Load a pre-trained object detection model from TensorFlow Hub\n",
        "model_url = \"https://tfhub.dev/tensorflow/ssd_mobilenet_v2/fpnlite_320x320/1\"\n",
        "detector = hub.load(model_url)\n",
        "\n",
        "# Function to load and preprocess image\n",
        "def load_image(image_path):\n",
        "    img = tf.io.read_file(image_path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "    return img\n",
        "\n",
        "# Function to draw bounding boxes\n",
        "def draw_boxes(image, boxes, class_names, scores, threshold=0.5):\n",
        "    image = np.array(image)\n",
        "    height, width, _ = image.shape\n",
        "    \n",
        "    for i in range(boxes.shape[0]):\n",
        "        if scores[i] >= threshold:\n",
        "            ymin, xmin, ymax, xmax = boxes[i]\n",
        "            xmin = int(xmin * width)\n",
        "            xmax = int(xmax * width)\n",
        "            ymin = int(ymin * height)\n",
        "            ymax = int(ymax * height)\n",
        "            \n",
        "            cv2.rectangle(image, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
        "            label = f\"{class_names[i].decode('ascii')}: {scores[i]:.2f}\"\n",
        "            cv2.putText(image, label, (xmin, ymin-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,0,0), 2)\n",
        "    return image\n",
        "\n",
        "# Load an image\n",
        "image_path = 'your_image.jpg'  # <-- replace with your test image path\n",
        "image = load_image(image_path)\n",
        "input_tensor = tf.expand_dims(image, 0)\n",
        "\n",
        "# Run detection\n",
        "detector_output = detector(input_tensor)\n",
        "\n",
        "# Extract boxes, class names, and scores\n",
        "boxes = detector_output['detection_boxes'][0].numpy()\n",
        "class_names = detector_output['detection_class_entities'][0].numpy()\n",
        "scores = detector_output['detection_scores'][0].numpy()\n",
        "\n",
        "# Draw detections\n",
        "result_img = draw_boxes(image, boxes, class_names, scores)\n",
        "\n",
        "# Show the result\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(result_img)\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d934305",
      "metadata": {
        "id": "4d934305"
      },
      "source": [
        "# Assignment 10"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5b3df47",
      "metadata": {
        "id": "c5b3df47"
      },
      "source": [
        "## Problem Statement:<br>\n",
        "Write Python program to implement CNN object detection. Discuss numerous performance evaluation metrics for evaluating the object-detecting algorithms' performance."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "038efb2e",
      "metadata": {
        "id": "038efb2e"
      },
      "source": [
        "### Import TensorFlow library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f6402f5d",
      "metadata": {
        "id": "f6402f5d"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e2cceac2",
      "metadata": {
        "id": "e2cceac2"
      },
      "outputs": [],
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9404f625",
      "metadata": {
        "id": "9404f625"
      },
      "source": [
        "### Preprocess the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "50446f30",
      "metadata": {
        "id": "50446f30"
      },
      "outputs": [],
      "source": [
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f3e20f6",
      "metadata": {
        "id": "6f3e20f6"
      },
      "source": [
        "### Add a channel dimension to the images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "67474a04",
      "metadata": {
        "id": "67474a04"
      },
      "outputs": [],
      "source": [
        "train_images = train_images.reshape(-1, 28, 28, 1)\n",
        "test_images = test_images.reshape(-1, 28, 28, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04326aea",
      "metadata": {
        "id": "04326aea"
      },
      "source": [
        "### Convert labels to one-hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "430ffd1b",
      "metadata": {
        "id": "430ffd1b"
      },
      "outputs": [],
      "source": [
        "train_labels = tf.keras.utils.to_categorical(train_labels, num_classes=10)\n",
        "test_labels = tf.keras.utils.to_categorical(test_labels, num_classes=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1677a385",
      "metadata": {
        "id": "1677a385"
      },
      "source": [
        "### Define the CNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "e8051061",
      "metadata": {
        "id": "e8051061"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b41e3542",
      "metadata": {
        "id": "b41e3542"
      },
      "source": [
        "### Compile the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "7b88722f",
      "metadata": {
        "id": "7b88722f"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04899df4",
      "metadata": {
        "id": "04899df4"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "245a80f7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "245a80f7",
        "outputId": "81f1c434-9240-4ecb-b020-96d6e88d4014"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "1875/1875 [==============================] - 30s 16ms/step - loss: 0.1642 - accuracy: 0.9516\n",
            "Epoch 2/4\n",
            "1875/1875 [==============================] - 29s 15ms/step - loss: 0.0565 - accuracy: 0.9826\n",
            "Epoch 3/4\n",
            "1875/1875 [==============================] - 27s 15ms/step - loss: 0.0388 - accuracy: 0.9880\n",
            "Epoch 4/4\n",
            "1875/1875 [==============================] - 27s 15ms/step - loss: 0.0272 - accuracy: 0.9913\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ee5a5c43910>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(train_images, train_labels, epochs=4, batch_size=32)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd34259d",
      "metadata": {
        "id": "dd34259d"
      },
      "source": [
        "### Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "6c5b7394",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6c5b7394",
        "outputId": "588ce676-8465-4a94-b328-59b92c3f3ae6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0429 - accuracy: 0.9869\n",
            "Test Loss: 0.0429\n",
            "Test Accuracy: 0.9869\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
